"{{endpoint}}":
  image: ghcr.io/huggingface/text-generation-inference:sha-e4201f4-intel-cpu
  container_name: "{{endpoint}}"
  ports:
    - "{{port}}:80"
  volumes:
    - "./data:/data"
  shm_size: 1g
  environment:
    no_proxy: ${no_proxy}
    http_proxy: ${http_proxy}
    https_proxy: ${https_proxy}
    HF_TOKEN: "{{huggingFaceToken}}"
    HF_HUB_DISABLE_PROGRESS_BARS: 1
    HF_HUB_ENABLE_HF_TRANSFER: 0
  command: --model-id {{modelName}} --cuda-graphs 0