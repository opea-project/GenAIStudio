"{{endpoint}}":
  image: ghcr.io/huggingface/text-generation-inference:2.4.0-intel-cpu
  container_name: "{{endpoint}}"
  ports:
    - "{{port_key}}:80"
  volumes:
    - "./data:/data"
  shm_size: 1g
  environment:
    no_proxy: ${no_proxy}
    http_proxy: ${http_proxy}
    https_proxy: ${https_proxy}
    HF_TOKEN: "{{huggingFaceToken}}"
    HF_HUB_DISABLE_PROGRESS_BARS: 1
    HF_HUB_ENABLE_HF_TRANSFER: 0
  command: --model-id {{modelName}} --cuda-graphs 0
  healthcheck:
    test: ["CMD", "curl", "-f", "http://localhost:80/health"]
    interval: 30s
    retries: 20
    timeout: 10s