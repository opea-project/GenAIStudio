"{{endpoint}}":
  image: ghcr.io/huggingface/text-embeddings-inference:cpu-1.5
  container_name: "{{endpoint}}"
  ports:
    - "{{port}}:80"
  volumes:
    - "./data:/data"
  shm_size: 1g
  environment:
    no_proxy: ${no_proxy}
    http_proxy: ${http_proxy}
    https_proxy: ${https_proxy}
  command: --model-id {{modelName}} --auto-truncate